{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-cKbdlg5_3B",
        "outputId": "ab04e37a-1076-41c8-e1e2-7fc8ce800b1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Input, Dense, Flatten, Dropout, Activation\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from tensorflow.keras.layers import Concatenate, GlobalAveragePooling2D, Reshape, Lambda\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "import numpy as np\n",
        "\n",
        "def load_mnist():\n",
        "    # Load data\n",
        "    (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "    # Reshape data to add channel dimension\n",
        "    X_train = np.expand_dims(X_train, -1)\n",
        "    X_test = np.expand_dims(X_test, -1)\n",
        "\n",
        "    # Normalize data\n",
        "    X_train = X_train.astype('float32') / 255.0\n",
        "    X_test = X_test.astype('float32') / 255.0\n",
        "\n",
        "    return (X_train, y_train), (X_test, y_test)\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = load_mnist()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GoO2PCnu6QoE"
      },
      "outputs": [],
      "source": [
        "# Base imports for model creation and compilation\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Input, Dense, Flatten, Dropout, Activation\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from tensorflow.keras.layers import Concatenate, Add, GlobalAveragePooling2D, AveragePooling2D\n",
        "from tensorflow.keras.layers import SeparableConv2D, Reshape, Lambda\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "# For functional API usage\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "# Additional utilities\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "\n",
        "# Make sure to use the correct imports as required for specific layers or utilities\n",
        "\n",
        "\n",
        "def create_vgg_like_model(input_shape):\n",
        "    model = Sequential()\n",
        "\n",
        "    # Block 1\n",
        "    model.add(Conv2D(64, (3, 3), padding='same', activation='relu', input_shape=input_shape))\n",
        "    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    # Block 2\n",
        "    model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
        "    model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    # Block 3\n",
        "    model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
        "    model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
        "    model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "def create_inception_like_model(input_shape):\n",
        "    inputs = Input(shape=input_shape)\n",
        "    # Tower 1\n",
        "    tower_1 = Conv2D(64, (1, 1), padding='same', activation='relu')(inputs)\n",
        "    tower_1 = Conv2D(64, (3, 3), padding='same', activation='relu')(tower_1)\n",
        "\n",
        "    # Tower 2\n",
        "    tower_2 = Conv2D(64, (1, 1), padding='same', activation='relu')(inputs)\n",
        "    tower_2 = Conv2D(64, (5, 5), padding='same', activation='relu')(tower_2)\n",
        "\n",
        "    # Tower 3\n",
        "    tower_3 = MaxPooling2D((3, 3), strides=(1, 1), padding='same')(inputs)\n",
        "    tower_3 = Conv2D(64, (1, 1), padding='same', activation='relu')(tower_3)\n",
        "\n",
        "    output = Concatenate(axis=-1)([tower_1, tower_2, tower_3])\n",
        "    output = Flatten()(output)\n",
        "    output = Dense(256, activation='relu')(output)\n",
        "    output = Dropout(0.4)(output)\n",
        "    output = Dense(10, activation='softmax')(output)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=output)\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def create_mobilenet_like_model(input_shape):\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, (3, 3), strides=(2, 2), padding='same', activation='relu', input_shape=input_shape))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    model.add(SeparableConv2D(64, (3, 3), padding='same', activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(SeparableConv2D(128, (3, 3), padding='same', activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def create_shallow_wide_model(input_shape):\n",
        "    model = Sequential([\n",
        "        Conv2D(256, (3, 3), padding='same', activation='relu', input_shape=input_shape),\n",
        "        Conv2D(256, (3, 3), padding='same', activation='relu'),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Flatten(),\n",
        "        Dense(256, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(10, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def create_asymmetric_convolution_model(input_shape):\n",
        "    model = Sequential([\n",
        "        Conv2D(64, (1, 3), padding='same', activation='relu', input_shape=input_shape),\n",
        "        Conv2D(64, (3, 1), padding='same', activation='relu'),\n",
        "        Conv2D(128, (1, 3), padding='same', activation='relu'),\n",
        "        Conv2D(128, (3, 1), padding='same', activation='relu'),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Flatten(),\n",
        "        Dense(256, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(10, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def create_capsule_inspired_model(input_shape):\n",
        "    model = Sequential([\n",
        "        Conv2D(64, (3, 3), activation='relu', input_shape=input_shape),\n",
        "        Conv2D(64, (3, 3), activation='relu'),\n",
        "        Flatten(),\n",
        "        Dense(160, activation='sigmoid'),  # Capsule-like dense layer\n",
        "        Reshape((10, 16)),  # 10 capsules, 16 dimensions each\n",
        "        Lambda(lambda x: K.sqrt(K.sum(K.square(x), axis=2))),  # Length of the vector as a capsule's output\n",
        "        Activation('softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def create_minimalistic_model(input_shape):\n",
        "    model = Sequential([\n",
        "        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Flatten(),\n",
        "        Dense(10, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def create_high_dropout_model(input_shape):\n",
        "    model = Sequential([\n",
        "        Conv2D(128, (3, 3), padding='same', activation='relu', input_shape=input_shape),\n",
        "        Dropout(0.5),\n",
        "        Conv2D(128, (3, 3), padding='same', activation='relu'),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Dropout(0.5),\n",
        "        Flatten(),\n",
        "        Dense(256, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(10, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def create_increased_bn_model(input_shape):\n",
        "    model = Sequential([\n",
        "        Conv2D(64, (3, 3), padding='same', activation='relu', input_shape=input_shape),\n",
        "        BatchNormalization(),\n",
        "        Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        BatchNormalization(),\n",
        "        Flatten(),\n",
        "        Dense(128, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        Dense(10, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "from tensorflow.keras.layers import Input, Conv2D ,Concatenate,BatchNormalization, ReLU, Add, MaxPooling2D, GlobalAveragePooling2D, Dense, AveragePooling2D\n",
        "\n",
        "def resnet_lite_block(input_tensor, filters, kernel_size, strides=(1, 1), activation='relu', l2_reg=0.001):\n",
        "    \"\"\"A simplified ResNet block.\"\"\"\n",
        "    x = Conv2D(filters, kernel_size, strides=strides, padding='same', kernel_regularizer=l2(l2_reg))(input_tensor)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "\n",
        "    x = Conv2D(filters, kernel_size, strides=(1, 1), padding='same', kernel_regularizer=l2(l2_reg))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    shortcut = Conv2D(filters, (1, 1), strides=strides, padding='same', kernel_regularizer=l2(l2_reg))(input_tensor)\n",
        "    shortcut = BatchNormalization()(shortcut)\n",
        "\n",
        "    x = Add()([x, shortcut])\n",
        "    x = ReLU()(x)\n",
        "    return x\n",
        "\n",
        "def create_extreme_resnet_model(input_shape):\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = inputs\n",
        "\n",
        "    # Add multiple residual blocks\n",
        "    for _ in range(5):  # Extreme ResNet with 5 blocks\n",
        "        x = resnet_lite_block(x, 64, (3, 3), l2_reg=0.001)\n",
        "    for _ in range(5):\n",
        "        x = resnet_lite_block(x, 128, (3, 3), l2_reg=0.001)\n",
        "\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(256, activation='relu')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Dense(10, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=x)\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFHBER3d6Tld",
        "outputId": "eb54de84-9d41-46be-fb17-3aaa88e35b8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training model: vgg_like\n",
            "Epoch 1/8\n",
            "938/938 [==============================] - 79s 83ms/step - loss: 0.1990 - accuracy: 0.9372 - val_loss: 0.0463 - val_accuracy: 0.9861\n",
            "Epoch 2/8\n",
            "938/938 [==============================] - 78s 83ms/step - loss: 0.0582 - accuracy: 0.9837 - val_loss: 0.0292 - val_accuracy: 0.9902\n",
            "Epoch 3/8\n",
            "938/938 [==============================] - 78s 83ms/step - loss: 0.0399 - accuracy: 0.9890 - val_loss: 0.0353 - val_accuracy: 0.9896\n",
            "Epoch 4/8\n",
            "938/938 [==============================] - 78s 83ms/step - loss: 0.0341 - accuracy: 0.9905 - val_loss: 0.0227 - val_accuracy: 0.9924\n",
            "Epoch 5/8\n",
            "938/938 [==============================] - 78s 83ms/step - loss: 0.0259 - accuracy: 0.9922 - val_loss: 0.0233 - val_accuracy: 0.9936\n",
            "Epoch 6/8\n",
            "938/938 [==============================] - 78s 83ms/step - loss: 0.0239 - accuracy: 0.9933 - val_loss: 0.0309 - val_accuracy: 0.9923\n",
            "Epoch 7/8\n",
            "938/938 [==============================] - 78s 83ms/step - loss: 0.0238 - accuracy: 0.9934 - val_loss: 0.0229 - val_accuracy: 0.9936\n",
            "Epoch 8/8\n",
            "938/938 [==============================] - 78s 83ms/step - loss: 0.0200 - accuracy: 0.9943 - val_loss: 0.0331 - val_accuracy: 0.9910\n",
            "Training model: inception_like\n",
            "Epoch 1/8\n",
            "938/938 [==============================] - 207s 219ms/step - loss: 0.1771 - accuracy: 0.9470 - val_loss: 0.0587 - val_accuracy: 0.9805\n",
            "Epoch 2/8\n",
            "938/938 [==============================] - 207s 221ms/step - loss: 0.0630 - accuracy: 0.9803 - val_loss: 0.0532 - val_accuracy: 0.9840\n",
            "Epoch 3/8\n",
            "938/938 [==============================] - 207s 221ms/step - loss: 0.0427 - accuracy: 0.9865 - val_loss: 0.0447 - val_accuracy: 0.9861\n",
            "Epoch 4/8\n",
            "938/938 [==============================] - 208s 222ms/step - loss: 0.0299 - accuracy: 0.9899 - val_loss: 0.0416 - val_accuracy: 0.9867\n",
            "Epoch 5/8\n",
            "938/938 [==============================] - 206s 219ms/step - loss: 0.0231 - accuracy: 0.9923 - val_loss: 0.0425 - val_accuracy: 0.9883\n",
            "Epoch 6/8\n",
            "938/938 [==============================] - 206s 220ms/step - loss: 0.0174 - accuracy: 0.9942 - val_loss: 0.0532 - val_accuracy: 0.9868\n",
            "Epoch 7/8\n",
            "938/938 [==============================] - 207s 220ms/step - loss: 0.0149 - accuracy: 0.9950 - val_loss: 0.0438 - val_accuracy: 0.9882\n",
            "Epoch 8/8\n",
            "938/938 [==============================] - 206s 220ms/step - loss: 0.0128 - accuracy: 0.9955 - val_loss: 0.0531 - val_accuracy: 0.9874\n",
            "Training model: mobilenet_like\n",
            "Epoch 1/8\n",
            "938/938 [==============================] - 19s 19ms/step - loss: 0.2335 - accuracy: 0.9310 - val_loss: 0.0666 - val_accuracy: 0.9785\n",
            "Epoch 2/8\n",
            "938/938 [==============================] - 17s 18ms/step - loss: 0.0929 - accuracy: 0.9733 - val_loss: 0.0468 - val_accuracy: 0.9859\n",
            "Epoch 3/8\n",
            "938/938 [==============================] - 17s 19ms/step - loss: 0.0722 - accuracy: 0.9797 - val_loss: 0.0411 - val_accuracy: 0.9868\n",
            "Epoch 4/8\n",
            "938/938 [==============================] - 17s 19ms/step - loss: 0.0577 - accuracy: 0.9837 - val_loss: 0.0367 - val_accuracy: 0.9893\n",
            "Epoch 5/8\n",
            "938/938 [==============================] - 17s 18ms/step - loss: 0.0483 - accuracy: 0.9859 - val_loss: 0.0392 - val_accuracy: 0.9888\n",
            "Epoch 6/8\n",
            "938/938 [==============================] - 17s 18ms/step - loss: 0.0445 - accuracy: 0.9872 - val_loss: 0.0360 - val_accuracy: 0.9891\n",
            "Epoch 7/8\n",
            "938/938 [==============================] - 17s 18ms/step - loss: 0.0381 - accuracy: 0.9886 - val_loss: 0.0586 - val_accuracy: 0.9866\n",
            "Epoch 8/8\n",
            "938/938 [==============================] - 17s 18ms/step - loss: 0.0367 - accuracy: 0.9891 - val_loss: 0.0495 - val_accuracy: 0.9902\n",
            "Training model: shallow_wide\n",
            "Epoch 1/8\n",
            "938/938 [==============================] - 275s 292ms/step - loss: 0.1388 - accuracy: 0.9573 - val_loss: 0.0364 - val_accuracy: 0.9876\n",
            "Epoch 2/8\n",
            "938/938 [==============================] - 275s 293ms/step - loss: 0.0548 - accuracy: 0.9836 - val_loss: 0.0298 - val_accuracy: 0.9901\n",
            "Epoch 3/8\n",
            "938/938 [==============================] - 274s 292ms/step - loss: 0.0372 - accuracy: 0.9879 - val_loss: 0.0306 - val_accuracy: 0.9907\n",
            "Epoch 4/8\n",
            "938/938 [==============================] - 277s 295ms/step - loss: 0.0303 - accuracy: 0.9905 - val_loss: 0.0241 - val_accuracy: 0.9926\n",
            "Epoch 5/8\n",
            "938/938 [==============================] - 276s 294ms/step - loss: 0.0227 - accuracy: 0.9926 - val_loss: 0.0280 - val_accuracy: 0.9920\n",
            "Epoch 6/8\n",
            "938/938 [==============================] - 278s 296ms/step - loss: 0.0188 - accuracy: 0.9937 - val_loss: 0.0292 - val_accuracy: 0.9912\n",
            "Epoch 7/8\n",
            "938/938 [==============================] - 277s 295ms/step - loss: 0.0155 - accuracy: 0.9949 - val_loss: 0.0286 - val_accuracy: 0.9921\n",
            "Epoch 8/8\n",
            "938/938 [==============================] - 276s 294ms/step - loss: 0.0143 - accuracy: 0.9951 - val_loss: 0.0311 - val_accuracy: 0.9918\n",
            "Training model: asymmetric_conv\n",
            "Epoch 1/8\n",
            "938/938 [==============================] - 56s 59ms/step - loss: 0.1486 - accuracy: 0.9553 - val_loss: 0.0388 - val_accuracy: 0.9866\n",
            "Epoch 2/8\n",
            "938/938 [==============================] - 56s 59ms/step - loss: 0.0555 - accuracy: 0.9826 - val_loss: 0.0312 - val_accuracy: 0.9898\n",
            "Epoch 3/8\n",
            "938/938 [==============================] - 55s 58ms/step - loss: 0.0378 - accuracy: 0.9880 - val_loss: 0.0265 - val_accuracy: 0.9902\n",
            "Epoch 4/8\n",
            "938/938 [==============================] - 54s 58ms/step - loss: 0.0281 - accuracy: 0.9912 - val_loss: 0.0348 - val_accuracy: 0.9898\n",
            "Epoch 5/8\n",
            "938/938 [==============================] - 55s 58ms/step - loss: 0.0233 - accuracy: 0.9923 - val_loss: 0.0286 - val_accuracy: 0.9913\n",
            "Epoch 6/8\n",
            "938/938 [==============================] - 55s 59ms/step - loss: 0.0203 - accuracy: 0.9931 - val_loss: 0.0336 - val_accuracy: 0.9906\n",
            "Epoch 7/8\n",
            "938/938 [==============================] - 55s 58ms/step - loss: 0.0161 - accuracy: 0.9944 - val_loss: 0.0330 - val_accuracy: 0.9911\n",
            "Epoch 8/8\n",
            "938/938 [==============================] - 55s 59ms/step - loss: 0.0147 - accuracy: 0.9952 - val_loss: 0.0261 - val_accuracy: 0.9936\n",
            "Training model: capsule_inspired\n",
            "Epoch 1/8\n",
            "938/938 [==============================] - 33s 34ms/step - loss: nan - accuracy: 0.1120 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 2/8\n",
            "938/938 [==============================] - 32s 35ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 3/8\n",
            "938/938 [==============================] - 33s 35ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 4/8\n",
            "938/938 [==============================] - 32s 35ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 5/8\n",
            "938/938 [==============================] - 32s 34ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 6/8\n",
            "938/938 [==============================] - 32s 34ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 7/8\n",
            "938/938 [==============================] - 32s 34ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 8/8\n",
            "938/938 [==============================] - 32s 34ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Training model: minimalistic\n",
            "Epoch 1/8\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.2709 - accuracy: 0.9247 - val_loss: 0.1043 - val_accuracy: 0.9712\n",
            "Epoch 2/8\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0919 - accuracy: 0.9738 - val_loss: 0.0706 - val_accuracy: 0.9782\n",
            "Epoch 3/8\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0667 - accuracy: 0.9807 - val_loss: 0.0619 - val_accuracy: 0.9795\n",
            "Epoch 4/8\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0553 - accuracy: 0.9836 - val_loss: 0.0557 - val_accuracy: 0.9827\n",
            "Epoch 5/8\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0486 - accuracy: 0.9856 - val_loss: 0.0514 - val_accuracy: 0.9836\n",
            "Epoch 6/8\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0428 - accuracy: 0.9872 - val_loss: 0.0519 - val_accuracy: 0.9832\n",
            "Epoch 7/8\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0380 - accuracy: 0.9888 - val_loss: 0.0535 - val_accuracy: 0.9818\n",
            "Epoch 8/8\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0339 - accuracy: 0.9897 - val_loss: 0.0523 - val_accuracy: 0.9835\n",
            "Training model: high_dropout\n",
            "Epoch 1/8\n",
            "938/938 [==============================] - 92s 97ms/step - loss: 0.1796 - accuracy: 0.9449 - val_loss: 0.0458 - val_accuracy: 0.9852\n",
            "Epoch 2/8\n",
            "938/938 [==============================] - 91s 97ms/step - loss: 0.0725 - accuracy: 0.9773 - val_loss: 0.0299 - val_accuracy: 0.9900\n",
            "Epoch 3/8\n",
            "938/938 [==============================] - 91s 97ms/step - loss: 0.0566 - accuracy: 0.9824 - val_loss: 0.0295 - val_accuracy: 0.9901\n",
            "Epoch 4/8\n",
            "938/938 [==============================] - 91s 97ms/step - loss: 0.0472 - accuracy: 0.9851 - val_loss: 0.0323 - val_accuracy: 0.9892\n",
            "Epoch 5/8\n",
            "938/938 [==============================] - 91s 97ms/step - loss: 0.0409 - accuracy: 0.9872 - val_loss: 0.0278 - val_accuracy: 0.9908\n",
            "Epoch 6/8\n",
            "938/938 [==============================] - 91s 97ms/step - loss: 0.0372 - accuracy: 0.9880 - val_loss: 0.0274 - val_accuracy: 0.9910\n",
            "Epoch 7/8\n",
            "938/938 [==============================] - 91s 97ms/step - loss: 0.0337 - accuracy: 0.9893 - val_loss: 0.0250 - val_accuracy: 0.9929\n",
            "Epoch 8/8\n",
            "938/938 [==============================] - 90s 96ms/step - loss: 0.0312 - accuracy: 0.9903 - val_loss: 0.0226 - val_accuracy: 0.9926\n",
            "Training model: increased_bn\n",
            "Epoch 1/8\n",
            "938/938 [==============================] - 43s 45ms/step - loss: 0.0971 - accuracy: 0.9711 - val_loss: 0.0648 - val_accuracy: 0.9792\n",
            "Epoch 2/8\n",
            "938/938 [==============================] - 41s 43ms/step - loss: 0.0349 - accuracy: 0.9893 - val_loss: 0.0311 - val_accuracy: 0.9897\n",
            "Epoch 3/8\n",
            "938/938 [==============================] - 41s 43ms/step - loss: 0.0224 - accuracy: 0.9926 - val_loss: 0.0350 - val_accuracy: 0.9886\n",
            "Epoch 4/8\n",
            "938/938 [==============================] - 41s 43ms/step - loss: 0.0143 - accuracy: 0.9956 - val_loss: 0.0486 - val_accuracy: 0.9837\n",
            "Epoch 5/8\n",
            "938/938 [==============================] - 40s 43ms/step - loss: 0.0134 - accuracy: 0.9958 - val_loss: 0.0488 - val_accuracy: 0.9855\n",
            "Epoch 6/8\n",
            "938/938 [==============================] - 40s 43ms/step - loss: 0.0091 - accuracy: 0.9972 - val_loss: 0.0343 - val_accuracy: 0.9904\n",
            "Epoch 7/8\n",
            "938/938 [==============================] - 40s 43ms/step - loss: 0.0077 - accuracy: 0.9975 - val_loss: 0.0415 - val_accuracy: 0.9874\n",
            "Epoch 8/8\n",
            "938/938 [==============================] - 41s 43ms/step - loss: 0.0054 - accuracy: 0.9983 - val_loss: 0.0475 - val_accuracy: 0.9865\n",
            "Training model: extreme_resnet\n",
            "Epoch 1/8\n",
            "938/938 [==============================] - 865s 913ms/step - loss: 1.1201 - accuracy: 0.9293 - val_loss: 1.0945 - val_accuracy: 0.7557\n",
            "Epoch 2/8\n",
            "938/938 [==============================] - 856s 912ms/step - loss: 0.3582 - accuracy: 0.9647 - val_loss: 0.4188 - val_accuracy: 0.9162\n",
            "Epoch 3/8\n",
            "938/938 [==============================] - 860s 916ms/step - loss: 0.2724 - accuracy: 0.9690 - val_loss: 1.3984 - val_accuracy: 0.7500\n",
            "Epoch 4/8\n",
            "938/938 [==============================] - 853s 910ms/step - loss: 0.2396 - accuracy: 0.9714 - val_loss: 2.8297 - val_accuracy: 0.4107\n",
            "Epoch 5/8\n",
            "938/938 [==============================] - 859s 916ms/step - loss: 0.2183 - accuracy: 0.9731 - val_loss: 0.3983 - val_accuracy: 0.9190\n",
            "Epoch 6/8\n",
            "938/938 [==============================] - 856s 912ms/step - loss: 0.1999 - accuracy: 0.9745 - val_loss: 0.2733 - val_accuracy: 0.9524\n",
            "Epoch 7/8\n",
            "938/938 [==============================] - 853s 910ms/step - loss: 0.1809 - accuracy: 0.9770 - val_loss: 0.2900 - val_accuracy: 0.9336\n",
            "Epoch 8/8\n",
            "938/938 [==============================] - 855s 912ms/step - loss: 0.1702 - accuracy: 0.9785 - val_loss: 0.3935 - val_accuracy: 0.8872\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "models = {\n",
        "    \"vgg_like\": create_vgg_like_model((28, 28, 1)),\n",
        "    \"inception_like\": create_inception_like_model((28, 28, 1)),\n",
        "    \"mobilenet_like\": create_mobilenet_like_model((28, 28, 1)),\n",
        "    \"shallow_wide\": create_shallow_wide_model((28, 28, 1)),\n",
        "    \"asymmetric_conv\": create_asymmetric_convolution_model((28, 28, 1)),\n",
        "    \"capsule_inspired\": create_capsule_inspired_model((28, 28, 1)),\n",
        "    \"minimalistic\": create_minimalistic_model((28, 28, 1)),\n",
        "    \"high_dropout\": create_high_dropout_model((28, 28, 1)),\n",
        "    \"increased_bn\": create_increased_bn_model((28, 28, 1)),\n",
        "    \"extreme_resnet\": create_extreme_resnet_model((28, 28, 1))\n",
        "}\n",
        "\n",
        "batch_size = 64\n",
        "epochs = 8\n",
        "\n",
        "# Loop to compile, train, and save each model\n",
        "for model_name, model in models.items():\n",
        "    print(f\"Training model: {model_name}\")\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Early stopping and model checkpoint\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "    model_checkpoint = ModelCheckpoint(f'/content/drive/My Drive/ood_generalization_proj/cnn_models/MNIST_models/checkpoints/{model_name}_best.h5', save_best_only=True)\n",
        "\n",
        "    # Fit the model\n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        batch_size=batch_size,\n",
        "        epochs=epochs,\n",
        "        validation_data=(X_test, y_test),\n",
        "        callbacks=[early_stopping, model_checkpoint]\n",
        "    )\n",
        "\n",
        "    # Optionally, you can save the final model (not just the best checkpoint)\n",
        "    model.save(f'/content/drive/My Drive/ood_generalization_proj/cnn_models/MNIST_models/{model_name}.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iGdTWb1V7HLj"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}