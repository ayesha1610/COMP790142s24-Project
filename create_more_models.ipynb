{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jFp6aAhgN3Vx"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.stats as ss\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "from scipy import sparse\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.neighbors import kneighbors_graph\n",
        "from skimage.transform import rotate\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras import layers, models\n",
        "from google.colab import drive\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXy4f51sOMq9",
        "outputId": "bb6829fa-3b00-4b67-bcba-7c764ee902b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_cifar10():\n",
        "    (X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "    return (X_train, y_train), (X_test, y_test)"
      ],
      "metadata": {
        "id": "7aQRhyCSPSbS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test) = load_cifar10()\n",
        "X_train = X_train.astype('float32') / 255.0\n",
        "X_test = X_test.astype('float32') / 255.0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awls_fhqOQxz",
        "outputId": "478e3d34-6362-49cf-b905-a00871512a81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 2s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Base imports for model creation and compilation\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Input, Dense, Flatten, Dropout, Activation\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from tensorflow.keras.layers import Concatenate, Add, GlobalAveragePooling2D, AveragePooling2D\n",
        "from tensorflow.keras.layers import SeparableConv2D, Reshape, Lambda\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "# For functional API usage\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "# Additional utilities\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "\n",
        "# Make sure to use the correct imports as required for specific layers or utilities\n",
        "\n",
        "\n",
        "def create_vgg_like_model(input_shape):\n",
        "    model = Sequential()\n",
        "\n",
        "    # Block 1\n",
        "    model.add(Conv2D(64, (3, 3), padding='same', activation='relu', input_shape=input_shape))\n",
        "    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    # Block 2\n",
        "    model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
        "    model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    # Block 3\n",
        "    model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
        "    model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
        "    model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "def create_inception_like_model(input_shape):\n",
        "    inputs = Input(shape=input_shape)\n",
        "    # Tower 1\n",
        "    tower_1 = Conv2D(64, (1, 1), padding='same', activation='relu')(inputs)\n",
        "    tower_1 = Conv2D(64, (3, 3), padding='same', activation='relu')(tower_1)\n",
        "\n",
        "    # Tower 2\n",
        "    tower_2 = Conv2D(64, (1, 1), padding='same', activation='relu')(inputs)\n",
        "    tower_2 = Conv2D(64, (5, 5), padding='same', activation='relu')(tower_2)\n",
        "\n",
        "    # Tower 3\n",
        "    tower_3 = MaxPooling2D((3, 3), strides=(1, 1), padding='same')(inputs)\n",
        "    tower_3 = Conv2D(64, (1, 1), padding='same', activation='relu')(tower_3)\n",
        "\n",
        "    output = Concatenate(axis=-1)([tower_1, tower_2, tower_3])\n",
        "    output = Flatten()(output)\n",
        "    output = Dense(256, activation='relu')(output)\n",
        "    output = Dropout(0.4)(output)\n",
        "    output = Dense(10, activation='softmax')(output)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=output)\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def create_mobilenet_like_model(input_shape):\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, (3, 3), strides=(2, 2), padding='same', activation='relu', input_shape=input_shape))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    model.add(SeparableConv2D(64, (3, 3), padding='same', activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(SeparableConv2D(128, (3, 3), padding='same', activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def create_shallow_wide_model(input_shape):\n",
        "    model = Sequential([\n",
        "        Conv2D(256, (3, 3), padding='same', activation='relu', input_shape=input_shape),\n",
        "        Conv2D(256, (3, 3), padding='same', activation='relu'),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Flatten(),\n",
        "        Dense(256, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(10, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def create_asymmetric_convolution_model(input_shape):\n",
        "    model = Sequential([\n",
        "        Conv2D(64, (1, 3), padding='same', activation='relu', input_shape=input_shape),\n",
        "        Conv2D(64, (3, 1), padding='same', activation='relu'),\n",
        "        Conv2D(128, (1, 3), padding='same', activation='relu'),\n",
        "        Conv2D(128, (3, 1), padding='same', activation='relu'),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Flatten(),\n",
        "        Dense(256, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(10, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def create_capsule_inspired_model(input_shape):\n",
        "    model = Sequential([\n",
        "        Conv2D(64, (3, 3), activation='relu', input_shape=input_shape),\n",
        "        Conv2D(64, (3, 3), activation='relu'),\n",
        "        Flatten(),\n",
        "        Dense(160, activation='sigmoid'),  # Capsule-like dense layer\n",
        "        Reshape((10, 16)),  # 10 capsules, 16 dimensions each\n",
        "        Lambda(lambda x: K.sqrt(K.sum(K.square(x), axis=2))),  # Length of the vector as a capsule's output\n",
        "        Activation('softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def create_minimalistic_model(input_shape):\n",
        "    model = Sequential([\n",
        "        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Flatten(),\n",
        "        Dense(10, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def create_high_dropout_model(input_shape):\n",
        "    model = Sequential([\n",
        "        Conv2D(128, (3, 3), padding='same', activation='relu', input_shape=input_shape),\n",
        "        Dropout(0.5),\n",
        "        Conv2D(128, (3, 3), padding='same', activation='relu'),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Dropout(0.5),\n",
        "        Flatten(),\n",
        "        Dense(256, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(10, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def create_increased_bn_model(input_shape):\n",
        "    model = Sequential([\n",
        "        Conv2D(64, (3, 3), padding='same', activation='relu', input_shape=input_shape),\n",
        "        BatchNormalization(),\n",
        "        Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        BatchNormalization(),\n",
        "        Flatten(),\n",
        "        Dense(128, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        Dense(10, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "from tensorflow.keras.layers import Input, Conv2D ,Concatenate,BatchNormalization, ReLU, Add, MaxPooling2D, GlobalAveragePooling2D, Dense, AveragePooling2D\n",
        "\n",
        "def resnet_lite_block(input_tensor, filters, kernel_size, strides=(1, 1), activation='relu', l2_reg=0.001):\n",
        "    \"\"\"A simplified ResNet block.\"\"\"\n",
        "    x = Conv2D(filters, kernel_size, strides=strides, padding='same', kernel_regularizer=l2(l2_reg))(input_tensor)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "\n",
        "    x = Conv2D(filters, kernel_size, strides=(1, 1), padding='same', kernel_regularizer=l2(l2_reg))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    shortcut = Conv2D(filters, (1, 1), strides=strides, padding='same', kernel_regularizer=l2(l2_reg))(input_tensor)\n",
        "    shortcut = BatchNormalization()(shortcut)\n",
        "\n",
        "    x = Add()([x, shortcut])\n",
        "    x = ReLU()(x)\n",
        "    return x\n",
        "\n",
        "def create_extreme_resnet_model(input_shape):\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = inputs\n",
        "\n",
        "    # Add multiple residual blocks\n",
        "    for _ in range(5):  # Extreme ResNet with 5 blocks\n",
        "        x = resnet_lite_block(x, 64, (3, 3), l2_reg=0.001)\n",
        "    for _ in range(5):\n",
        "        x = resnet_lite_block(x, 128, (3, 3), l2_reg=0.001)\n",
        "\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(256, activation='relu')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Dense(10, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=x)\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "UZJ6ubZtOVUW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "# Load CIFAR-10 data\n",
        "def load_cifar10():\n",
        "    (X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "    return (X_train, y_train), (X_test, y_test)\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = load_cifar10()\n",
        "X_train = X_train.astype('float32') / 255.0\n",
        "X_test = X_test.astype('float32') / 255.0\n",
        "\n",
        "# Define a dictionary of models\n",
        "models = {\n",
        "    \"vgg_like\": create_vgg_like_model((32, 32, 3)),\n",
        "    \"inception_like\": create_inception_like_model((32, 32, 3)),\n",
        "    \"mobilenet_like\": create_mobilenet_like_model((32, 32, 3)),\n",
        "    \"shallow_wide\": create_shallow_wide_model((32, 32, 3)),\n",
        "    \"asymmetric_conv\": create_asymmetric_convolution_model((32, 32, 3)),\n",
        "    \"capsule_inspired\": create_capsule_inspired_model((32, 32, 3)),\n",
        "    \"minimalistic\": create_minimalistic_model((32, 32, 3)),\n",
        "    \"high_dropout\": create_high_dropout_model((32, 32, 3)),\n",
        "    \"increased_bn\": create_increased_bn_model((32, 32, 3)),\n",
        "    \"extreme_resnet\": create_extreme_resnet_model((32, 32, 3))\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "# Training settings\n",
        "batch_size = 64\n",
        "epochs = 30\n",
        "\n",
        "# Loop to compile, train, and save each model\n",
        "for model_name, model in models.items():\n",
        "    print(f\"Training model: {model_name}\")\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Early stopping and model checkpoint\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "    model_checkpoint = ModelCheckpoint(f'/content/drive/My Drive/ood_generalization_proj/cnn_models/checkpoints/{model_name}_best.h5', save_best_only=True)\n",
        "\n",
        "    # Fit the model\n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        batch_size=batch_size,\n",
        "        epochs=epochs,\n",
        "        validation_data=(X_test, y_test),\n",
        "        callbacks=[early_stopping, model_checkpoint]\n",
        "    )\n",
        "\n",
        "    # Optionally, you can save the final model (not just the best checkpoint)\n",
        "    model.save(f'/content/drive/My Drive/ood_generalization_proj/cnn_models/{model_name}.keras')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4VlYhMAOPdvr",
        "outputId": "d2a82eff-8dc0-4db9-cde4-8a607c315bf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training model: vgg_like\n",
            "Epoch 1/20\n",
            "781/782 [============================>.] - ETA: 0s - loss: 1.7656 - accuracy: 0.3323"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 83s 105ms/step - loss: 1.7655 - accuracy: 0.3323 - val_loss: 1.4620 - val_accuracy: 0.4659\n",
            "Epoch 2/20\n",
            "782/782 [==============================] - 80s 102ms/step - loss: 1.2836 - accuracy: 0.5375 - val_loss: 1.0739 - val_accuracy: 0.6213\n",
            "Epoch 3/20\n",
            "782/782 [==============================] - 79s 101ms/step - loss: 1.0258 - accuracy: 0.6387 - val_loss: 0.9025 - val_accuracy: 0.6847\n",
            "Epoch 4/20\n",
            "782/782 [==============================] - 80s 102ms/step - loss: 0.8517 - accuracy: 0.7054 - val_loss: 0.8372 - val_accuracy: 0.7146\n",
            "Epoch 5/20\n",
            "782/782 [==============================] - 80s 103ms/step - loss: 0.7328 - accuracy: 0.7496 - val_loss: 0.7353 - val_accuracy: 0.7502\n",
            "Epoch 6/20\n",
            "782/782 [==============================] - 79s 102ms/step - loss: 0.6379 - accuracy: 0.7832 - val_loss: 0.7460 - val_accuracy: 0.7490\n",
            "Epoch 7/20\n",
            "782/782 [==============================] - 80s 102ms/step - loss: 0.5561 - accuracy: 0.8093 - val_loss: 0.6955 - val_accuracy: 0.7751\n",
            "Epoch 8/20\n",
            "782/782 [==============================] - 80s 103ms/step - loss: 0.4960 - accuracy: 0.8302 - val_loss: 0.6780 - val_accuracy: 0.7861\n",
            "Epoch 9/20\n",
            "782/782 [==============================] - 79s 101ms/step - loss: 0.4341 - accuracy: 0.8504 - val_loss: 0.7075 - val_accuracy: 0.7751\n",
            "Epoch 10/20\n",
            "782/782 [==============================] - 79s 101ms/step - loss: 0.3850 - accuracy: 0.8665 - val_loss: 0.7232 - val_accuracy: 0.7775\n",
            "Epoch 11/20\n",
            "782/782 [==============================] - 78s 100ms/step - loss: 0.3482 - accuracy: 0.8795 - val_loss: 0.7458 - val_accuracy: 0.7825\n",
            "Epoch 12/20\n",
            "782/782 [==============================] - 79s 101ms/step - loss: 0.3170 - accuracy: 0.8893 - val_loss: 0.7557 - val_accuracy: 0.7847\n",
            "Epoch 13/20\n",
            "782/782 [==============================] - 79s 101ms/step - loss: 0.2848 - accuracy: 0.9032 - val_loss: 0.8326 - val_accuracy: 0.7888\n",
            "Epoch 14/20\n",
            "782/782 [==============================] - 79s 101ms/step - loss: 0.2577 - accuracy: 0.9092 - val_loss: 0.8663 - val_accuracy: 0.7823\n",
            "Epoch 15/20\n",
            "782/782 [==============================] - 78s 100ms/step - loss: 0.2450 - accuracy: 0.9150 - val_loss: 0.9367 - val_accuracy: 0.7805\n",
            "Epoch 16/20\n",
            "782/782 [==============================] - 78s 100ms/step - loss: 0.2238 - accuracy: 0.9229 - val_loss: 1.0217 - val_accuracy: 0.7844\n",
            "Epoch 17/20\n",
            "782/782 [==============================] - 78s 100ms/step - loss: 0.2164 - accuracy: 0.9267 - val_loss: 0.9881 - val_accuracy: 0.7805\n",
            "Epoch 18/20\n",
            "782/782 [==============================] - 78s 100ms/step - loss: 0.2084 - accuracy: 0.9305 - val_loss: 1.0545 - val_accuracy: 0.7841\n",
            "Training model: inception_like\n",
            "Epoch 1/20\n",
            "782/782 [==============================] - 225s 286ms/step - loss: 2.0185 - accuracy: 0.2747 - val_loss: 1.5950 - val_accuracy: 0.4414\n",
            "Epoch 2/20\n",
            "782/782 [==============================] - 228s 291ms/step - loss: 1.6694 - accuracy: 0.3808 - val_loss: 1.4089 - val_accuracy: 0.4913\n",
            "Epoch 3/20\n",
            "782/782 [==============================] - 226s 290ms/step - loss: 1.5110 - accuracy: 0.4434 - val_loss: 1.3427 - val_accuracy: 0.5241\n",
            "Epoch 4/20\n",
            "782/782 [==============================] - 228s 292ms/step - loss: 1.4198 - accuracy: 0.4828 - val_loss: 1.2604 - val_accuracy: 0.5423\n",
            "Epoch 5/20\n",
            "782/782 [==============================] - 226s 289ms/step - loss: 1.3418 - accuracy: 0.5130 - val_loss: 1.2323 - val_accuracy: 0.5643\n",
            "Epoch 6/20\n",
            "782/782 [==============================] - 227s 291ms/step - loss: 1.2736 - accuracy: 0.5394 - val_loss: 1.1888 - val_accuracy: 0.5800\n",
            "Epoch 7/20\n",
            "782/782 [==============================] - 228s 292ms/step - loss: 1.2021 - accuracy: 0.5668 - val_loss: 1.1695 - val_accuracy: 0.5880\n",
            "Epoch 8/20\n",
            "782/782 [==============================] - 227s 291ms/step - loss: 1.1406 - accuracy: 0.5880 - val_loss: 1.1458 - val_accuracy: 0.5948\n",
            "Epoch 9/20\n",
            "782/782 [==============================] - 230s 294ms/step - loss: 1.0819 - accuracy: 0.6084 - val_loss: 1.1319 - val_accuracy: 0.6057\n",
            "Epoch 10/20\n",
            "782/782 [==============================] - 228s 292ms/step - loss: 1.0306 - accuracy: 0.6256 - val_loss: 1.1251 - val_accuracy: 0.6079\n",
            "Epoch 11/20\n",
            "782/782 [==============================] - 223s 286ms/step - loss: 0.9802 - accuracy: 0.6424 - val_loss: 1.1436 - val_accuracy: 0.6040\n",
            "Epoch 12/20\n",
            "782/782 [==============================] - 225s 288ms/step - loss: 0.9369 - accuracy: 0.6577 - val_loss: 1.1417 - val_accuracy: 0.6122\n",
            "Epoch 13/20\n",
            "782/782 [==============================] - 224s 287ms/step - loss: 0.8879 - accuracy: 0.6755 - val_loss: 1.1753 - val_accuracy: 0.6064\n",
            "Epoch 14/20\n",
            "782/782 [==============================] - 224s 286ms/step - loss: 0.8463 - accuracy: 0.6887 - val_loss: 1.1713 - val_accuracy: 0.6116\n",
            "Epoch 15/20\n",
            "782/782 [==============================] - 225s 288ms/step - loss: 0.8115 - accuracy: 0.7015 - val_loss: 1.1780 - val_accuracy: 0.6066\n",
            "Epoch 16/20\n",
            "782/782 [==============================] - 225s 288ms/step - loss: 0.7628 - accuracy: 0.7179 - val_loss: 1.2590 - val_accuracy: 0.6072\n",
            "Epoch 17/20\n",
            "782/782 [==============================] - 224s 287ms/step - loss: 0.7215 - accuracy: 0.7321 - val_loss: 1.2905 - val_accuracy: 0.6086\n",
            "Epoch 18/20\n",
            "782/782 [==============================] - 223s 285ms/step - loss: 0.6958 - accuracy: 0.7418 - val_loss: 1.2832 - val_accuracy: 0.6116\n",
            "Epoch 19/20\n",
            "782/782 [==============================] - 225s 288ms/step - loss: 0.6578 - accuracy: 0.7550 - val_loss: 1.3324 - val_accuracy: 0.6086\n",
            "Epoch 20/20\n",
            "782/782 [==============================] - 225s 287ms/step - loss: 0.6318 - accuracy: 0.7654 - val_loss: 1.3289 - val_accuracy: 0.6098\n",
            "Training model: mobilenet_like\n",
            "Epoch 1/20\n",
            "782/782 [==============================] - 17s 20ms/step - loss: 1.6171 - accuracy: 0.4271 - val_loss: 1.2381 - val_accuracy: 0.5620\n",
            "Epoch 2/20\n",
            "782/782 [==============================] - 15s 20ms/step - loss: 1.2212 - accuracy: 0.5702 - val_loss: 1.1081 - val_accuracy: 0.6227\n",
            "Epoch 3/20\n",
            "782/782 [==============================] - 16s 20ms/step - loss: 1.0441 - accuracy: 0.6348 - val_loss: 0.9753 - val_accuracy: 0.6593\n",
            "Epoch 4/20\n",
            "782/782 [==============================] - 15s 19ms/step - loss: 0.9103 - accuracy: 0.6783 - val_loss: 1.0455 - val_accuracy: 0.6578\n",
            "Epoch 5/20\n",
            "782/782 [==============================] - 15s 20ms/step - loss: 0.8135 - accuracy: 0.7127 - val_loss: 0.9450 - val_accuracy: 0.6752\n",
            "Epoch 6/20\n",
            "782/782 [==============================] - 16s 20ms/step - loss: 0.7318 - accuracy: 0.7407 - val_loss: 0.9410 - val_accuracy: 0.6848\n",
            "Epoch 7/20\n",
            "782/782 [==============================] - 15s 19ms/step - loss: 0.6661 - accuracy: 0.7652 - val_loss: 0.9610 - val_accuracy: 0.6855\n",
            "Epoch 8/20\n",
            "782/782 [==============================] - 15s 19ms/step - loss: 0.5956 - accuracy: 0.7877 - val_loss: 0.9931 - val_accuracy: 0.6962\n",
            "Epoch 9/20\n",
            "782/782 [==============================] - 15s 19ms/step - loss: 0.5473 - accuracy: 0.8006 - val_loss: 1.0282 - val_accuracy: 0.6872\n",
            "Epoch 10/20\n",
            "782/782 [==============================] - 15s 20ms/step - loss: 0.5132 - accuracy: 0.8159 - val_loss: 1.0249 - val_accuracy: 0.6892\n",
            "Epoch 11/20\n",
            "782/782 [==============================] - 15s 20ms/step - loss: 0.4744 - accuracy: 0.8293 - val_loss: 1.0881 - val_accuracy: 0.6855\n",
            "Epoch 12/20\n",
            "782/782 [==============================] - 15s 19ms/step - loss: 0.4335 - accuracy: 0.8448 - val_loss: 1.1090 - val_accuracy: 0.7008\n",
            "Epoch 13/20\n",
            "782/782 [==============================] - 15s 19ms/step - loss: 0.4205 - accuracy: 0.8490 - val_loss: 1.1643 - val_accuracy: 0.6997\n",
            "Epoch 14/20\n",
            "782/782 [==============================] - 15s 19ms/step - loss: 0.3907 - accuracy: 0.8581 - val_loss: 1.1378 - val_accuracy: 0.7002\n",
            "Epoch 15/20\n",
            "782/782 [==============================] - 15s 19ms/step - loss: 0.3747 - accuracy: 0.8648 - val_loss: 1.1413 - val_accuracy: 0.6995\n",
            "Epoch 16/20\n",
            "782/782 [==============================] - 15s 19ms/step - loss: 0.3538 - accuracy: 0.8706 - val_loss: 1.2109 - val_accuracy: 0.6908\n",
            "Training model: shallow_wide\n",
            "Epoch 1/20\n",
            "782/782 [==============================] - 333s 425ms/step - loss: 1.5985 - accuracy: 0.4250 - val_loss: 1.2439 - val_accuracy: 0.5620\n",
            "Epoch 2/20\n",
            "782/782 [==============================] - 335s 428ms/step - loss: 1.2474 - accuracy: 0.5567 - val_loss: 1.0647 - val_accuracy: 0.6259\n",
            "Epoch 3/20\n",
            "782/782 [==============================] - 336s 429ms/step - loss: 1.1051 - accuracy: 0.6116 - val_loss: 1.0384 - val_accuracy: 0.6350\n",
            "Epoch 4/20\n",
            "782/782 [==============================] - 337s 431ms/step - loss: 1.0098 - accuracy: 0.6417 - val_loss: 0.9630 - val_accuracy: 0.6602\n",
            "Epoch 5/20\n",
            "782/782 [==============================] - 336s 430ms/step - loss: 0.9390 - accuracy: 0.6690 - val_loss: 0.9426 - val_accuracy: 0.6678\n",
            "Epoch 6/20\n",
            "782/782 [==============================] - 335s 428ms/step - loss: 0.8774 - accuracy: 0.6883 - val_loss: 0.9569 - val_accuracy: 0.6671\n",
            "Epoch 7/20\n",
            "782/782 [==============================] - 337s 431ms/step - loss: 0.8203 - accuracy: 0.7095 - val_loss: 0.9324 - val_accuracy: 0.6822\n",
            "Epoch 8/20\n",
            "782/782 [==============================] - 335s 429ms/step - loss: 0.7720 - accuracy: 0.7245 - val_loss: 0.9433 - val_accuracy: 0.6785\n",
            "Epoch 9/20\n",
            "782/782 [==============================] - 337s 430ms/step - loss: 0.7201 - accuracy: 0.7425 - val_loss: 0.9212 - val_accuracy: 0.6919\n",
            "Epoch 10/20\n",
            "782/782 [==============================] - 333s 426ms/step - loss: 0.6764 - accuracy: 0.7551 - val_loss: 0.9399 - val_accuracy: 0.6867\n",
            "Epoch 11/20\n",
            "782/782 [==============================] - 334s 428ms/step - loss: 0.6291 - accuracy: 0.7721 - val_loss: 0.9671 - val_accuracy: 0.6812\n",
            "Epoch 12/20\n",
            "782/782 [==============================] - 335s 428ms/step - loss: 0.5934 - accuracy: 0.7852 - val_loss: 0.9680 - val_accuracy: 0.6859\n",
            "Epoch 13/20\n",
            "782/782 [==============================] - 335s 429ms/step - loss: 0.5556 - accuracy: 0.7973 - val_loss: 0.9983 - val_accuracy: 0.6941\n",
            "Epoch 14/20\n",
            "782/782 [==============================] - 335s 429ms/step - loss: 0.5255 - accuracy: 0.8099 - val_loss: 1.0300 - val_accuracy: 0.6848\n",
            "Epoch 15/20\n",
            "782/782 [==============================] - 335s 428ms/step - loss: 0.5054 - accuracy: 0.8157 - val_loss: 1.0362 - val_accuracy: 0.6832\n",
            "Epoch 16/20\n",
            "782/782 [==============================] - 335s 429ms/step - loss: 0.4709 - accuracy: 0.8275 - val_loss: 1.0722 - val_accuracy: 0.6879\n",
            "Epoch 17/20\n",
            "782/782 [==============================] - 335s 428ms/step - loss: 0.4532 - accuracy: 0.8330 - val_loss: 1.0721 - val_accuracy: 0.6838\n",
            "Epoch 18/20\n",
            "782/782 [==============================] - 334s 427ms/step - loss: 0.4353 - accuracy: 0.8403 - val_loss: 1.1399 - val_accuracy: 0.6883\n",
            "Epoch 19/20\n",
            "782/782 [==============================] - 334s 427ms/step - loss: 0.4058 - accuracy: 0.8510 - val_loss: 1.2033 - val_accuracy: 0.6764\n",
            "Training model: asymmetric_conv\n",
            "Epoch 1/20\n",
            "782/782 [==============================] - 77s 97ms/step - loss: 1.5007 - accuracy: 0.4582 - val_loss: 1.1499 - val_accuracy: 0.5897\n",
            "Epoch 2/20\n",
            "782/782 [==============================] - 75s 96ms/step - loss: 1.1263 - accuracy: 0.6024 - val_loss: 0.9927 - val_accuracy: 0.6511\n",
            "Epoch 3/20\n",
            "782/782 [==============================] - 76s 97ms/step - loss: 0.9532 - accuracy: 0.6634 - val_loss: 0.8885 - val_accuracy: 0.6853\n",
            "Epoch 4/20\n",
            "782/782 [==============================] - 75s 95ms/step - loss: 0.8204 - accuracy: 0.7103 - val_loss: 0.8597 - val_accuracy: 0.6941\n",
            "Epoch 5/20\n",
            "782/782 [==============================] - 77s 98ms/step - loss: 0.7005 - accuracy: 0.7510 - val_loss: 0.8557 - val_accuracy: 0.6998\n",
            "Epoch 6/20\n",
            "782/782 [==============================] - 75s 96ms/step - loss: 0.5952 - accuracy: 0.7860 - val_loss: 0.8769 - val_accuracy: 0.7091\n",
            "Epoch 7/20\n",
            "782/782 [==============================] - 75s 97ms/step - loss: 0.5028 - accuracy: 0.8176 - val_loss: 0.8779 - val_accuracy: 0.7152\n",
            "Epoch 8/20\n",
            "782/782 [==============================] - 75s 96ms/step - loss: 0.4290 - accuracy: 0.8450 - val_loss: 0.9731 - val_accuracy: 0.7061\n",
            "Epoch 9/20\n",
            "782/782 [==============================] - 76s 97ms/step - loss: 0.3757 - accuracy: 0.8637 - val_loss: 1.0084 - val_accuracy: 0.7014\n",
            "Epoch 10/20\n",
            "782/782 [==============================] - 75s 96ms/step - loss: 0.3317 - accuracy: 0.8791 - val_loss: 1.0490 - val_accuracy: 0.7113\n",
            "Epoch 11/20\n",
            "782/782 [==============================] - 76s 98ms/step - loss: 0.2902 - accuracy: 0.8919 - val_loss: 1.1699 - val_accuracy: 0.7137\n",
            "Epoch 12/20\n",
            "782/782 [==============================] - 75s 96ms/step - loss: 0.2750 - accuracy: 0.8992 - val_loss: 1.1683 - val_accuracy: 0.7040\n",
            "Epoch 13/20\n",
            "782/782 [==============================] - 75s 96ms/step - loss: 0.2442 - accuracy: 0.9098 - val_loss: 1.1974 - val_accuracy: 0.7101\n",
            "Epoch 14/20\n",
            "782/782 [==============================] - 75s 96ms/step - loss: 0.2363 - accuracy: 0.9136 - val_loss: 1.2917 - val_accuracy: 0.7099\n",
            "Epoch 15/20\n",
            "782/782 [==============================] - 76s 97ms/step - loss: 0.2157 - accuracy: 0.9208 - val_loss: 1.3516 - val_accuracy: 0.7088\n",
            "Training model: capsule_inspired\n",
            "Epoch 1/20\n",
            "782/782 [==============================] - 36s 46ms/step - loss: 1.4855 - accuracy: 0.4822 - val_loss: 1.2989 - val_accuracy: 0.5560\n",
            "Epoch 2/20\n",
            "782/782 [==============================] - 35s 45ms/step - loss: nan - accuracy: 0.4687 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 3/20\n",
            "782/782 [==============================] - 35s 45ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 4/20\n",
            "782/782 [==============================] - 35s 45ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 5/20\n",
            "782/782 [==============================] - 35s 44ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 6/20\n",
            "782/782 [==============================] - 34s 44ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 7/20\n",
            "782/782 [==============================] - 34s 44ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 8/20\n",
            "782/782 [==============================] - 35s 45ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 9/20\n",
            "782/782 [==============================] - 36s 46ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 10/20\n",
            "782/782 [==============================] - 35s 45ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Epoch 11/20\n",
            "782/782 [==============================] - 34s 44ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n",
            "Training model: minimalistic\n",
            "Epoch 1/20\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.5031 - accuracy: 0.4736 - val_loss: 1.3026 - val_accuracy: 0.5468\n",
            "Epoch 2/20\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.2218 - accuracy: 0.5765 - val_loss: 1.2133 - val_accuracy: 0.5706\n",
            "Epoch 3/20\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.1353 - accuracy: 0.6074 - val_loss: 1.1765 - val_accuracy: 0.5829\n",
            "Epoch 4/20\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.0641 - accuracy: 0.6335 - val_loss: 1.1292 - val_accuracy: 0.6022\n",
            "Epoch 5/20\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.0115 - accuracy: 0.6507 - val_loss: 1.0977 - val_accuracy: 0.6194\n",
            "Epoch 6/20\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 0.9743 - accuracy: 0.6662 - val_loss: 1.0506 - val_accuracy: 0.6332\n",
            "Epoch 7/20\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 0.9357 - accuracy: 0.6784 - val_loss: 1.0472 - val_accuracy: 0.6349\n",
            "Epoch 8/20\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 0.9073 - accuracy: 0.6867 - val_loss: 1.0302 - val_accuracy: 0.6447\n",
            "Epoch 9/20\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 0.8821 - accuracy: 0.6968 - val_loss: 1.0797 - val_accuracy: 0.6158\n",
            "Epoch 10/20\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 0.8594 - accuracy: 0.7067 - val_loss: 1.0858 - val_accuracy: 0.6210\n",
            "Epoch 11/20\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 0.8386 - accuracy: 0.7131 - val_loss: 1.0090 - val_accuracy: 0.6531\n",
            "Epoch 12/20\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 0.8184 - accuracy: 0.7192 - val_loss: 1.0509 - val_accuracy: 0.6452\n",
            "Epoch 13/20\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 0.7994 - accuracy: 0.7264 - val_loss: 1.0657 - val_accuracy: 0.6417\n",
            "Epoch 14/20\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 0.7815 - accuracy: 0.7323 - val_loss: 1.0171 - val_accuracy: 0.6540\n",
            "Epoch 15/20\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 0.7681 - accuracy: 0.7356 - val_loss: 1.0552 - val_accuracy: 0.6432\n",
            "Epoch 16/20\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 0.7553 - accuracy: 0.7416 - val_loss: 1.0442 - val_accuracy: 0.6486\n",
            "Epoch 17/20\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 0.7377 - accuracy: 0.7471 - val_loss: 1.1065 - val_accuracy: 0.6309\n",
            "Epoch 18/20\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 0.7242 - accuracy: 0.7519 - val_loss: 1.1074 - val_accuracy: 0.6327\n",
            "Epoch 19/20\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 0.7162 - accuracy: 0.7545 - val_loss: 1.0535 - val_accuracy: 0.6466\n",
            "Epoch 20/20\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 0.7039 - accuracy: 0.7589 - val_loss: 1.0749 - val_accuracy: 0.6416\n",
            "Training model: high_dropout\n",
            "Epoch 1/20\n",
            "782/782 [==============================] - 108s 138ms/step - loss: 1.6900 - accuracy: 0.3859 - val_loss: 1.3254 - val_accuracy: 0.5366\n",
            "Epoch 2/20\n",
            "782/782 [==============================] - 112s 144ms/step - loss: 1.3904 - accuracy: 0.5028 - val_loss: 1.2259 - val_accuracy: 0.5686\n",
            "Epoch 3/20\n",
            "782/782 [==============================] - 111s 142ms/step - loss: 1.2692 - accuracy: 0.5492 - val_loss: 1.1098 - val_accuracy: 0.6157\n",
            "Epoch 4/20\n",
            "782/782 [==============================] - 112s 143ms/step - loss: 1.1839 - accuracy: 0.5817 - val_loss: 1.0562 - val_accuracy: 0.6357\n",
            "Epoch 5/20\n",
            "782/782 [==============================] - 112s 144ms/step - loss: 1.1146 - accuracy: 0.6043 - val_loss: 1.0327 - val_accuracy: 0.6367\n",
            "Epoch 6/20\n",
            "782/782 [==============================] - 112s 143ms/step - loss: 1.0712 - accuracy: 0.6195 - val_loss: 0.9686 - val_accuracy: 0.6597\n",
            "Epoch 7/20\n",
            "782/782 [==============================] - 110s 140ms/step - loss: 1.0312 - accuracy: 0.6339 - val_loss: 0.9606 - val_accuracy: 0.6655\n",
            "Epoch 8/20\n",
            "782/782 [==============================] - 110s 140ms/step - loss: 0.9903 - accuracy: 0.6498 - val_loss: 0.9577 - val_accuracy: 0.6639\n",
            "Epoch 9/20\n",
            "782/782 [==============================] - 110s 141ms/step - loss: 0.9609 - accuracy: 0.6569 - val_loss: 0.9237 - val_accuracy: 0.6839\n",
            "Epoch 10/20\n",
            "782/782 [==============================] - 110s 141ms/step - loss: 0.9393 - accuracy: 0.6664 - val_loss: 0.9112 - val_accuracy: 0.6878\n",
            "Epoch 11/20\n",
            "782/782 [==============================] - 108s 139ms/step - loss: 0.9085 - accuracy: 0.6759 - val_loss: 0.9024 - val_accuracy: 0.6850\n",
            "Epoch 12/20\n",
            "782/782 [==============================] - 108s 138ms/step - loss: 0.8906 - accuracy: 0.6838 - val_loss: 0.9144 - val_accuracy: 0.6869\n",
            "Epoch 13/20\n",
            "782/782 [==============================] - 111s 141ms/step - loss: 0.8658 - accuracy: 0.6923 - val_loss: 0.8512 - val_accuracy: 0.7027\n",
            "Epoch 14/20\n",
            "782/782 [==============================] - 109s 139ms/step - loss: 0.8504 - accuracy: 0.6979 - val_loss: 0.8555 - val_accuracy: 0.7049\n",
            "Epoch 15/20\n",
            "782/782 [==============================] - 112s 143ms/step - loss: 0.8381 - accuracy: 0.7046 - val_loss: 0.8451 - val_accuracy: 0.7070\n",
            "Epoch 16/20\n",
            "782/782 [==============================] - 110s 140ms/step - loss: 0.8179 - accuracy: 0.7058 - val_loss: 0.8644 - val_accuracy: 0.6988\n",
            "Epoch 17/20\n",
            "782/782 [==============================] - 110s 140ms/step - loss: 0.8093 - accuracy: 0.7097 - val_loss: 0.8498 - val_accuracy: 0.7052\n",
            "Epoch 18/20\n",
            "782/782 [==============================] - 112s 143ms/step - loss: 0.7975 - accuracy: 0.7134 - val_loss: 0.8337 - val_accuracy: 0.7079\n",
            "Epoch 19/20\n",
            "782/782 [==============================] - 109s 139ms/step - loss: 0.7776 - accuracy: 0.7239 - val_loss: 0.8632 - val_accuracy: 0.6966\n",
            "Epoch 20/20\n",
            "782/782 [==============================] - 109s 139ms/step - loss: 0.7624 - accuracy: 0.7271 - val_loss: 0.8333 - val_accuracy: 0.7144\n",
            "Training model: increased_bn\n",
            "Epoch 1/20\n",
            "782/782 [==============================] - 45s 55ms/step - loss: 1.1771 - accuracy: 0.5872 - val_loss: 1.1030 - val_accuracy: 0.6304\n",
            "Epoch 2/20\n",
            "782/782 [==============================] - 44s 56ms/step - loss: 0.7741 - accuracy: 0.7302 - val_loss: 1.2059 - val_accuracy: 0.6056\n",
            "Epoch 3/20\n",
            "782/782 [==============================] - 44s 56ms/step - loss: 0.5374 - accuracy: 0.8162 - val_loss: 0.9004 - val_accuracy: 0.7009\n",
            "Epoch 4/20\n",
            "782/782 [==============================] - 43s 55ms/step - loss: 0.3252 - accuracy: 0.8927 - val_loss: 0.9993 - val_accuracy: 0.6855\n",
            "Epoch 5/20\n",
            "782/782 [==============================] - 42s 54ms/step - loss: 0.1831 - accuracy: 0.9419 - val_loss: 1.1397 - val_accuracy: 0.6954\n",
            "Epoch 6/20\n",
            "782/782 [==============================] - 43s 54ms/step - loss: 0.1106 - accuracy: 0.9663 - val_loss: 1.4930 - val_accuracy: 0.6836\n",
            "Epoch 7/20\n",
            "782/782 [==============================] - 43s 55ms/step - loss: 0.0805 - accuracy: 0.9748 - val_loss: 1.3109 - val_accuracy: 0.6768\n",
            "Epoch 8/20\n",
            "782/782 [==============================] - 42s 54ms/step - loss: 0.0697 - accuracy: 0.9781 - val_loss: 1.5477 - val_accuracy: 0.6913\n",
            "Epoch 9/20\n",
            "782/782 [==============================] - 42s 54ms/step - loss: 0.0638 - accuracy: 0.9795 - val_loss: 1.5123 - val_accuracy: 0.6989\n",
            "Epoch 10/20\n",
            "782/782 [==============================] - 43s 55ms/step - loss: 0.0600 - accuracy: 0.9804 - val_loss: 1.7786 - val_accuracy: 0.6631\n",
            "Epoch 11/20\n",
            "782/782 [==============================] - 43s 55ms/step - loss: 0.0589 - accuracy: 0.9808 - val_loss: 1.5662 - val_accuracy: 0.6698\n",
            "Epoch 12/20\n",
            "782/782 [==============================] - 43s 54ms/step - loss: 0.0455 - accuracy: 0.9851 - val_loss: 1.6273 - val_accuracy: 0.6891\n",
            "Epoch 13/20\n",
            "782/782 [==============================] - 43s 55ms/step - loss: 0.0381 - accuracy: 0.9886 - val_loss: 1.6768 - val_accuracy: 0.6811\n",
            "Training model: extreme_resnet\n",
            "Epoch 1/20\n",
            "782/782 [==============================] - 1131s 1s/step - loss: 2.4355 - accuracy: 0.3708 - val_loss: 3.1738 - val_accuracy: 0.2275\n",
            "Epoch 2/20\n",
            "782/782 [==============================] - 1118s 1s/step - loss: 1.5537 - accuracy: 0.5076 - val_loss: 2.2095 - val_accuracy: 0.3581\n",
            "Epoch 3/20\n",
            "782/782 [==============================] - 1122s 1s/step - loss: 1.4187 - accuracy: 0.5495 - val_loss: 2.2061 - val_accuracy: 0.3775\n",
            "Epoch 4/20\n",
            "782/782 [==============================] - 1121s 1s/step - loss: 1.3430 - accuracy: 0.5870 - val_loss: 4.4415 - val_accuracy: 0.1774\n",
            "Epoch 5/20\n",
            "782/782 [==============================] - 1128s 1s/step - loss: 1.2965 - accuracy: 0.6033 - val_loss: 2.0719 - val_accuracy: 0.3813\n",
            "Epoch 6/20\n",
            "782/782 [==============================] - 1129s 1s/step - loss: 1.2381 - accuracy: 0.6283 - val_loss: 2.3009 - val_accuracy: 0.3772\n",
            "Epoch 7/20\n",
            "782/782 [==============================] - 1128s 1s/step - loss: 1.1899 - accuracy: 0.6471 - val_loss: 1.8295 - val_accuracy: 0.3998\n",
            "Epoch 8/20\n",
            "782/782 [==============================] - 1123s 1s/step - loss: 1.1404 - accuracy: 0.6666 - val_loss: 9.0744 - val_accuracy: 0.2361\n",
            "Epoch 9/20\n",
            "782/782 [==============================] - 1121s 1s/step - loss: 1.1120 - accuracy: 0.6791 - val_loss: 1.7738 - val_accuracy: 0.4989\n",
            "Epoch 10/20\n",
            "782/782 [==============================] - 1121s 1s/step - loss: 1.0870 - accuracy: 0.6861 - val_loss: 1.9407 - val_accuracy: 0.3991\n",
            "Epoch 11/20\n",
            "782/782 [==============================] - 1127s 1s/step - loss: 1.0509 - accuracy: 0.6990 - val_loss: 1.3479 - val_accuracy: 0.6043\n",
            "Epoch 12/20\n",
            "782/782 [==============================] - 1124s 1s/step - loss: 1.0353 - accuracy: 0.7070 - val_loss: 2.1797 - val_accuracy: 0.4311\n",
            "Epoch 13/20\n",
            "782/782 [==============================] - 1120s 1s/step - loss: 1.0130 - accuracy: 0.7144 - val_loss: 1.9168 - val_accuracy: 0.4908\n",
            "Epoch 14/20\n",
            "782/782 [==============================] - 1116s 1s/step - loss: 0.9849 - accuracy: 0.7258 - val_loss: 1.5083 - val_accuracy: 0.5520\n",
            "Epoch 15/20\n",
            "782/782 [==============================] - 1124s 1s/step - loss: 0.9750 - accuracy: 0.7305 - val_loss: 1.2887 - val_accuracy: 0.6411\n",
            "Epoch 16/20\n",
            "782/782 [==============================] - 1124s 1s/step - loss: 0.9580 - accuracy: 0.7371 - val_loss: 1.8011 - val_accuracy: 0.4971\n",
            "Epoch 17/20\n",
            "782/782 [==============================] - 1124s 1s/step - loss: 0.9321 - accuracy: 0.7461 - val_loss: 1.5184 - val_accuracy: 0.5736\n",
            "Epoch 18/20\n",
            "782/782 [==============================] - 1122s 1s/step - loss: 0.9262 - accuracy: 0.7485 - val_loss: 1.3895 - val_accuracy: 0.6257\n",
            "Epoch 19/20\n",
            "559/782 [====================>.........] - ETA: 5:09 - loss: 0.9031 - accuracy: 0.7549"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_large_kernel_model(input_shape):\n",
        "    model = Sequential([\n",
        "        Conv2D(32, (5, 5), activation='relu', input_shape=input_shape, padding='same'),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Conv2D(64, (5, 5), activation='relu', padding='same'),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Flatten(),\n",
        "        Dense(256, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(10, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def create_multi_scale_features_model(input_shape):\n",
        "    inputs = Input(shape=input_shape)\n",
        "    branch1 = Conv2D(32, (1, 1), padding='same', activation='relu')(inputs)\n",
        "    branch2 = Conv2D(32, (3, 3), padding='same', activation='relu')(inputs)\n",
        "    branch3 = Conv2D(32, (5, 5), padding='same', activation='relu')(inputs)\n",
        "    output = Concatenate()([branch1, branch2, branch3])\n",
        "    output = Flatten()(output)\n",
        "    output = Dense(256, activation='relu')(output)\n",
        "    output = Dropout(0.5)(output)\n",
        "    output = Dense(10, activation='softmax')(output)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=output)\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, Add, Input, Flatten, Dense, Dropout, Activation\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "def create_skip_connection_model(input_shape):\n",
        "    inputs = Input(shape=input_shape)\n",
        "    # Adjust input tensor channels to match subsequent layers\n",
        "    adjusted_input = Conv2D(64, (1, 1), padding='same', activation='relu')(inputs)\n",
        "\n",
        "    # Main convolutional path\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    # Skip connection adding the adjusted input with the result of the main path\n",
        "    skip = Add()([adjusted_input, x])\n",
        "    skip = Activation('relu')(skip)  # Optional activation layer after adding\n",
        "\n",
        "    skip = Flatten()(skip)\n",
        "    skip = Dense(256, activation='relu')(skip)\n",
        "    skip = Dropout(0.5)(skip)\n",
        "    output = Dense(10, activation='softmax')(skip)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=output)\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "def create_dual_path_network_model(input_shape):\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    # Path 1\n",
        "    path1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    path1 = Conv2D(64, (3, 3), activation='relu', padding='same')(path1)\n",
        "\n",
        "    # Path 2\n",
        "    path2 = SeparableConv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    path2 = SeparableConv2D(64, (3, 3), activation='relu', padding='same')(path2)\n",
        "\n",
        "    combined = Concatenate()([path1, path2])\n",
        "    combined = Flatten()(combined)\n",
        "    combined = Dense(256, activation='relu')(combined)\n",
        "    combined = Dropout(0.5)(combined)\n",
        "    output = Dense(10, activation='softmax')(combined)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=output)\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def create_dense_prediction_model(input_shape):\n",
        "    model = Sequential([\n",
        "        Conv2D(64, (3, 3), activation='relu', input_shape=input_shape, padding='same'),\n",
        "        Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dense(128, activation='relu'),\n",
        "        Flatten(),\n",
        "        Dense(256, activation='relu'),\n",
        "        Dense(10, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n"
      ],
      "metadata": {
        "id": "HiMF2VK4QloL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = {\n",
        "    \"large_kernel_model\": create_large_kernel_model((32, 32, 3)),\n",
        "    \"multi_scale_features_model\": create_multi_scale_features_model((32, 32, 3)),\n",
        "    \"skip_connection_model\": create_skip_connection_model((32, 32, 3)),\n",
        "    \"dual_path_network_model\": create_dual_path_network_model((32, 32, 3)),\n",
        "    \"dense_prediction_model\": create_dense_prediction_model((32, 32, 3))\n",
        "}\n",
        "\n",
        "batch_size = 64\n",
        "epochs = 20\n",
        "\n",
        "# Directory for saving models and checkpoints\n",
        "model_dir = '/content/drive/My Drive/ood_generalization_proj/cnn_models'\n",
        "checkpoint_dir = f'{model_dir}/checkpoints'\n",
        "\n",
        "# Loop to compile, train, and save each model\n",
        "for model_name, model in models.items():\n",
        "    print(f\"Training model: {model_name}\")\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Early stopping and model checkpoint\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "    model_checkpoint = ModelCheckpoint(f'{checkpoint_dir}/{model_name}_best.h5', save_best_only=True)\n",
        "\n",
        "    # Fit the model\n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        batch_size=batch_size,\n",
        "        epochs=epochs,\n",
        "        validation_data=(X_test, y_test),\n",
        "        callbacks=[early_stopping, model_checkpoint]\n",
        "    )\n",
        "\n",
        "    # Save the final model\n",
        "    model.save(f'{model_dir}/{model_name}.keras')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "COuTdGYDxJ-O",
        "outputId": "4b5b18a8-ed3b-4190-a52a-d5d85062b8e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training model: large_kernel_model\n",
            "Epoch 1/20\n",
            "782/782 [==============================] - 17s 21ms/step - loss: 1.5528 - accuracy: 0.4382 - val_loss: 1.2495 - val_accuracy: 0.5498\n",
            "Epoch 2/20\n",
            "782/782 [==============================] - 17s 21ms/step - loss: 1.2200 - accuracy: 0.5651 - val_loss: 1.1250 - val_accuracy: 0.5991\n",
            "Epoch 3/20\n",
            "782/782 [==============================] - 17s 21ms/step - loss: 1.0719 - accuracy: 0.6209 - val_loss: 0.9477 - val_accuracy: 0.6664\n",
            "Epoch 4/20\n",
            "782/782 [==============================] - 17s 21ms/step - loss: 0.9728 - accuracy: 0.6578 - val_loss: 0.9227 - val_accuracy: 0.6767\n",
            "Epoch 5/20\n",
            "782/782 [==============================] - 17s 21ms/step - loss: 0.8856 - accuracy: 0.6867 - val_loss: 0.8804 - val_accuracy: 0.6950\n",
            "Epoch 6/20\n",
            "782/782 [==============================] - 17s 21ms/step - loss: 0.8144 - accuracy: 0.7138 - val_loss: 0.8499 - val_accuracy: 0.7033\n",
            "Epoch 7/20\n",
            "782/782 [==============================] - 16s 21ms/step - loss: 0.7511 - accuracy: 0.7342 - val_loss: 0.8464 - val_accuracy: 0.7068\n",
            "Epoch 8/20\n",
            "782/782 [==============================] - 16s 21ms/step - loss: 0.6991 - accuracy: 0.7517 - val_loss: 0.8586 - val_accuracy: 0.7084\n",
            "Epoch 9/20\n",
            "782/782 [==============================] - 16s 21ms/step - loss: 0.6507 - accuracy: 0.7701 - val_loss: 0.8407 - val_accuracy: 0.7174\n",
            "Epoch 10/20\n",
            "782/782 [==============================] - 16s 21ms/step - loss: 0.5995 - accuracy: 0.7875 - val_loss: 0.8682 - val_accuracy: 0.7106\n",
            "Epoch 11/20\n",
            "782/782 [==============================] - 16s 21ms/step - loss: 0.5608 - accuracy: 0.7996 - val_loss: 0.8728 - val_accuracy: 0.7180\n",
            "Epoch 12/20\n",
            "782/782 [==============================] - 16s 21ms/step - loss: 0.5190 - accuracy: 0.8126 - val_loss: 0.8667 - val_accuracy: 0.7218\n",
            "Epoch 13/20\n",
            "782/782 [==============================] - 16s 20ms/step - loss: 0.4832 - accuracy: 0.8275 - val_loss: 0.9644 - val_accuracy: 0.7040\n",
            "Epoch 14/20\n",
            "782/782 [==============================] - 16s 21ms/step - loss: 0.4535 - accuracy: 0.8354 - val_loss: 0.9492 - val_accuracy: 0.7152\n",
            "Epoch 15/20\n",
            "782/782 [==============================] - 16s 20ms/step - loss: 0.4334 - accuracy: 0.8436 - val_loss: 0.9669 - val_accuracy: 0.7123\n",
            "Epoch 16/20\n",
            "782/782 [==============================] - 16s 21ms/step - loss: 0.3983 - accuracy: 0.8564 - val_loss: 1.0257 - val_accuracy: 0.7150\n",
            "Epoch 17/20\n",
            "782/782 [==============================] - 16s 21ms/step - loss: 0.3835 - accuracy: 0.8607 - val_loss: 0.9956 - val_accuracy: 0.7194\n",
            "Epoch 18/20\n",
            "782/782 [==============================] - 16s 21ms/step - loss: 0.3532 - accuracy: 0.8699 - val_loss: 1.0692 - val_accuracy: 0.7167\n",
            "Epoch 19/20\n",
            "782/782 [==============================] - 16s 20ms/step - loss: 0.3381 - accuracy: 0.8756 - val_loss: 1.1191 - val_accuracy: 0.7152\n",
            "Training model: multi_scale_features_model\n",
            "Epoch 1/20\n",
            "782/782 [==============================] - 94s 119ms/step - loss: 2.0788 - accuracy: 0.2361 - val_loss: 1.6311 - val_accuracy: 0.4210\n",
            "Epoch 2/20\n",
            "782/782 [==============================] - 95s 122ms/step - loss: 1.6941 - accuracy: 0.3582 - val_loss: 1.4122 - val_accuracy: 0.5001\n",
            "Epoch 3/20\n",
            "782/782 [==============================] - 96s 123ms/step - loss: 1.5488 - accuracy: 0.4235 - val_loss: 1.3214 - val_accuracy: 0.5229\n",
            "Epoch 4/20\n",
            "782/782 [==============================] - 97s 124ms/step - loss: 1.4288 - accuracy: 0.4723 - val_loss: 1.2277 - val_accuracy: 0.5660\n",
            "Epoch 5/20\n",
            "782/782 [==============================] - 97s 123ms/step - loss: 1.3472 - accuracy: 0.5046 - val_loss: 1.2151 - val_accuracy: 0.5653\n",
            "Epoch 6/20\n",
            "782/782 [==============================] - 98s 125ms/step - loss: 1.2690 - accuracy: 0.5306 - val_loss: 1.1554 - val_accuracy: 0.5910\n",
            "Epoch 7/20\n",
            "782/782 [==============================] - 98s 126ms/step - loss: 1.2068 - accuracy: 0.5538 - val_loss: 1.1389 - val_accuracy: 0.5942\n",
            "Epoch 8/20\n",
            "782/782 [==============================] - 97s 124ms/step - loss: 1.1416 - accuracy: 0.5788 - val_loss: 1.1056 - val_accuracy: 0.6124\n",
            "Epoch 9/20\n",
            "782/782 [==============================] - 96s 123ms/step - loss: 1.0870 - accuracy: 0.5958 - val_loss: 1.1154 - val_accuracy: 0.6193\n",
            "Epoch 10/20\n",
            "782/782 [==============================] - 97s 124ms/step - loss: 1.0407 - accuracy: 0.6123 - val_loss: 1.1061 - val_accuracy: 0.6144\n",
            "Epoch 11/20\n",
            "782/782 [==============================] - 97s 125ms/step - loss: 0.9900 - accuracy: 0.6308 - val_loss: 1.1250 - val_accuracy: 0.6165\n",
            "Epoch 12/20\n",
            "782/782 [==============================] - 97s 124ms/step - loss: 0.9486 - accuracy: 0.6432 - val_loss: 1.1056 - val_accuracy: 0.6198\n",
            "Epoch 13/20\n",
            "782/782 [==============================] - 97s 124ms/step - loss: 0.9054 - accuracy: 0.6594 - val_loss: 1.1076 - val_accuracy: 0.6321\n",
            "Epoch 14/20\n",
            "782/782 [==============================] - 97s 124ms/step - loss: 0.8701 - accuracy: 0.6742 - val_loss: 1.1409 - val_accuracy: 0.6173\n",
            "Epoch 15/20\n",
            "782/782 [==============================] - 98s 125ms/step - loss: 0.8298 - accuracy: 0.6864 - val_loss: 1.1613 - val_accuracy: 0.6226\n",
            "Epoch 16/20\n",
            "782/782 [==============================] - 98s 125ms/step - loss: 0.7958 - accuracy: 0.6950 - val_loss: 1.1647 - val_accuracy: 0.6329\n",
            "Epoch 17/20\n",
            "782/782 [==============================] - 98s 125ms/step - loss: 0.7725 - accuracy: 0.7069 - val_loss: 1.1713 - val_accuracy: 0.6250\n",
            "Epoch 18/20\n",
            "782/782 [==============================] - 97s 124ms/step - loss: 0.7304 - accuracy: 0.7211 - val_loss: 1.2162 - val_accuracy: 0.6310\n",
            "Training model: skip_connection_model\n",
            "Epoch 1/20\n",
            "782/782 [==============================] - 88s 111ms/step - loss: 2.5237 - accuracy: 0.1427 - val_loss: 1.9808 - val_accuracy: 0.2181\n",
            "Epoch 2/20\n",
            "782/782 [==============================] - 87s 111ms/step - loss: 2.1082 - accuracy: 0.1604 - val_loss: 2.0285 - val_accuracy: 0.1570\n",
            "Epoch 3/20\n",
            "782/782 [==============================] - 89s 113ms/step - loss: 2.0836 - accuracy: 0.1651 - val_loss: 1.8656 - val_accuracy: 0.2309\n",
            "Epoch 4/20\n",
            "782/782 [==============================] - 86s 110ms/step - loss: 2.0618 - accuracy: 0.1770 - val_loss: 1.8673 - val_accuracy: 0.2981\n",
            "Epoch 5/20\n",
            "782/782 [==============================] - 88s 113ms/step - loss: 2.0518 - accuracy: 0.1848 - val_loss: 1.8084 - val_accuracy: 0.2930\n",
            "Epoch 6/20\n",
            "782/782 [==============================] - 86s 110ms/step - loss: 2.0392 - accuracy: 0.1884 - val_loss: 1.9227 - val_accuracy: 0.2145\n",
            "Epoch 7/20\n",
            "782/782 [==============================] - 87s 112ms/step - loss: 2.0270 - accuracy: 0.2006 - val_loss: 1.9107 - val_accuracy: 0.2732\n",
            "Epoch 8/20\n",
            "782/782 [==============================] - 87s 111ms/step - loss: 2.0191 - accuracy: 0.2009 - val_loss: 1.8524 - val_accuracy: 0.2871\n",
            "Epoch 9/20\n",
            "782/782 [==============================] - 86s 110ms/step - loss: 2.0062 - accuracy: 0.2095 - val_loss: 1.8478 - val_accuracy: 0.2805\n",
            "Epoch 10/20\n",
            "782/782 [==============================] - 88s 112ms/step - loss: 1.9991 - accuracy: 0.2114 - val_loss: 1.7971 - val_accuracy: 0.2908\n",
            "Epoch 11/20\n",
            "782/782 [==============================] - 89s 113ms/step - loss: 1.9885 - accuracy: 0.2163 - val_loss: 1.7640 - val_accuracy: 0.3152\n",
            "Epoch 12/20\n",
            "782/782 [==============================] - 88s 112ms/step - loss: 1.8697 - accuracy: 0.2657 - val_loss: 1.6005 - val_accuracy: 0.3968\n",
            "Epoch 13/20\n",
            "782/782 [==============================] - 89s 113ms/step - loss: 1.8003 - accuracy: 0.2821 - val_loss: 1.5629 - val_accuracy: 0.3953\n",
            "Epoch 14/20\n",
            "782/782 [==============================] - 88s 113ms/step - loss: 1.7424 - accuracy: 0.2936 - val_loss: 1.5030 - val_accuracy: 0.4196\n",
            "Epoch 15/20\n",
            "782/782 [==============================] - 88s 113ms/step - loss: 1.6994 - accuracy: 0.3094 - val_loss: 1.4992 - val_accuracy: 0.4417\n",
            "Epoch 16/20\n",
            "782/782 [==============================] - 87s 111ms/step - loss: 1.6486 - accuracy: 0.3271 - val_loss: 1.5253 - val_accuracy: 0.4311\n",
            "Epoch 17/20\n",
            "782/782 [==============================] - 90s 115ms/step - loss: 1.6092 - accuracy: 0.3446 - val_loss: 1.4903 - val_accuracy: 0.4677\n",
            "Epoch 18/20\n",
            "782/782 [==============================] - 89s 114ms/step - loss: 1.5867 - accuracy: 0.3556 - val_loss: 1.4379 - val_accuracy: 0.4822\n",
            "Epoch 19/20\n",
            "782/782 [==============================] - 87s 112ms/step - loss: 1.5622 - accuracy: 0.3698 - val_loss: 1.4902 - val_accuracy: 0.4826\n",
            "Epoch 20/20\n",
            "782/782 [==============================] - 90s 115ms/step - loss: 1.5306 - accuracy: 0.3868 - val_loss: 1.4076 - val_accuracy: 0.5104\n",
            "Training model: dual_path_network_model\n",
            "Epoch 1/20\n",
            "782/782 [==============================] - 133s 168ms/step - loss: 1.5745 - accuracy: 0.4400 - val_loss: 1.1824 - val_accuracy: 0.5818\n",
            "Epoch 2/20\n",
            "782/782 [==============================] - 132s 169ms/step - loss: 1.2006 - accuracy: 0.5742 - val_loss: 1.0737 - val_accuracy: 0.6241\n",
            "Epoch 3/20\n",
            "782/782 [==============================] - 134s 172ms/step - loss: 1.0287 - accuracy: 0.6372 - val_loss: 0.9936 - val_accuracy: 0.6498\n",
            "Epoch 4/20\n",
            "782/782 [==============================] - 133s 170ms/step - loss: 0.8842 - accuracy: 0.6866 - val_loss: 0.9732 - val_accuracy: 0.6614\n",
            "Epoch 5/20\n",
            "782/782 [==============================] - 135s 173ms/step - loss: 0.7683 - accuracy: 0.7251 - val_loss: 0.9521 - val_accuracy: 0.6716\n",
            "Epoch 6/20\n",
            "782/782 [==============================] - 131s 167ms/step - loss: 0.6422 - accuracy: 0.7692 - val_loss: 0.9941 - val_accuracy: 0.6726\n",
            "Epoch 7/20\n",
            "782/782 [==============================] - 132s 169ms/step - loss: 0.5434 - accuracy: 0.8056 - val_loss: 1.0139 - val_accuracy: 0.6783\n",
            "Epoch 8/20\n",
            "782/782 [==============================] - 132s 169ms/step - loss: 0.4608 - accuracy: 0.8355 - val_loss: 1.0849 - val_accuracy: 0.6724\n",
            "Epoch 9/20\n",
            "782/782 [==============================] - 133s 170ms/step - loss: 0.3862 - accuracy: 0.8597 - val_loss: 1.1735 - val_accuracy: 0.6722\n",
            "Epoch 10/20\n",
            "782/782 [==============================] - 135s 173ms/step - loss: 0.3313 - accuracy: 0.8811 - val_loss: 1.2536 - val_accuracy: 0.6750\n",
            "Epoch 11/20\n",
            "782/782 [==============================] - 135s 172ms/step - loss: 0.2999 - accuracy: 0.8911 - val_loss: 1.2833 - val_accuracy: 0.6669\n",
            "Epoch 12/20\n",
            "782/782 [==============================] - 135s 173ms/step - loss: 0.2677 - accuracy: 0.9025 - val_loss: 1.3301 - val_accuracy: 0.6733\n",
            "Epoch 13/20\n",
            "782/782 [==============================] - 136s 174ms/step - loss: 0.2381 - accuracy: 0.9144 - val_loss: 1.4013 - val_accuracy: 0.6752\n",
            "Epoch 14/20\n",
            "782/782 [==============================] - 135s 172ms/step - loss: 0.2209 - accuracy: 0.9202 - val_loss: 1.4857 - val_accuracy: 0.6676\n",
            "Epoch 15/20\n",
            "782/782 [==============================] - 135s 173ms/step - loss: 0.2063 - accuracy: 0.9248 - val_loss: 1.5351 - val_accuracy: 0.6730\n",
            "Training model: dense_prediction_model\n",
            "Epoch 1/20\n",
            "782/782 [==============================] - 52s 65ms/step - loss: 1.3929 - accuracy: 0.4982 - val_loss: 1.1065 - val_accuracy: 0.6040\n",
            "Epoch 2/20\n",
            "782/782 [==============================] - 51s 65ms/step - loss: 0.9376 - accuracy: 0.6658 - val_loss: 0.9157 - val_accuracy: 0.6792\n",
            "Epoch 3/20\n",
            "782/782 [==============================] - 51s 65ms/step - loss: 0.7086 - accuracy: 0.7513 - val_loss: 0.8336 - val_accuracy: 0.7116\n",
            "Epoch 4/20\n",
            "782/782 [==============================] - 50s 63ms/step - loss: 0.4936 - accuracy: 0.8287 - val_loss: 0.9841 - val_accuracy: 0.6930\n",
            "Epoch 5/20\n",
            "782/782 [==============================] - 50s 63ms/step - loss: 0.2906 - accuracy: 0.8979 - val_loss: 1.1974 - val_accuracy: 0.6882\n",
            "Epoch 6/20\n",
            "782/782 [==============================] - 49s 63ms/step - loss: 0.1550 - accuracy: 0.9471 - val_loss: 1.3269 - val_accuracy: 0.6867\n",
            "Epoch 7/20\n",
            "782/782 [==============================] - 52s 66ms/step - loss: 0.0988 - accuracy: 0.9662 - val_loss: 1.5599 - val_accuracy: 0.6829\n",
            "Epoch 8/20\n",
            "782/782 [==============================] - 52s 67ms/step - loss: 0.0776 - accuracy: 0.9740 - val_loss: 1.7891 - val_accuracy: 0.6829\n",
            "Epoch 9/20\n",
            "782/782 [==============================] - 51s 66ms/step - loss: 0.0671 - accuracy: 0.9774 - val_loss: 1.9236 - val_accuracy: 0.6934\n",
            "Epoch 10/20\n",
            "782/782 [==============================] - 51s 65ms/step - loss: 0.0605 - accuracy: 0.9787 - val_loss: 1.9787 - val_accuracy: 0.6797\n",
            "Epoch 11/20\n",
            "782/782 [==============================] - 51s 65ms/step - loss: 0.0524 - accuracy: 0.9818 - val_loss: 2.1305 - val_accuracy: 0.6703\n",
            "Epoch 12/20\n",
            "782/782 [==============================] - 51s 65ms/step - loss: 0.0484 - accuracy: 0.9842 - val_loss: 2.0465 - val_accuracy: 0.6864\n",
            "Epoch 13/20\n",
            "782/782 [==============================] - 50s 64ms/step - loss: 0.0542 - accuracy: 0.9820 - val_loss: 2.1175 - val_accuracy: 0.6750\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras import datasets, layers, models\n",
        "from keras.layers import Dense, Dropout, BatchNormalization, Conv2D, MaxPooling2D, Flatten\n",
        "from keras.regularizers import l2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Load dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
        "\n",
        "# Standardize images\n",
        "train_images = train_images.astype('float32') / 255\n",
        "test_images = test_images.astype('float32') / 255\n",
        "\n",
        "# Flatten the label arrays\n",
        "train_labels = train_labels.flatten()\n",
        "test_labels = test_labels.flatten()\n",
        "\n",
        "# Model architecture with added residual connections and data augmentation\n",
        "model = Sequential([\n",
        "    layers.RandomFlip(\"horizontal\"),\n",
        "    layers.RandomRotation(0.2),\n",
        "    layers.RandomZoom(0.2),\n",
        "\n",
        "    layers.Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=(32, 32, 3)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Conv2D(32, (3, 3), padding='same', activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "    layers.Dropout(0.3),\n",
        "\n",
        "    layers.Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "    layers.Dropout(0.5),\n",
        "\n",
        "    layers.Conv2D(128, (3, 3), padding='same', activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Conv2D(128, (3, 3), padding='same', activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "    layers.Dropout(0.5),\n",
        "\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu', kernel_regularizer=l2(0.01)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(10, activation='softmax')  # 10 classes\n",
        "])\n",
        "\n",
        "# Compile model with the sparse categorical crossentropy loss\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(train_images, train_labels, batch_size=64, epochs=30, validation_data=(test_images, test_labels))\n",
        "\n",
        "model.save(f'{model_dir}/augment_triple_depth.keras')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptdUKW75xRKr",
        "outputId": "989e21b8-baab-4fec-e564-fd2b90ea617f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "782/782 [==============================] - 52s 61ms/step - loss: 3.0483 - accuracy: 0.3224 - val_loss: 1.8665 - val_accuracy: 0.4336\n",
            "Epoch 2/30\n",
            "782/782 [==============================] - 47s 60ms/step - loss: 1.8669 - accuracy: 0.4220 - val_loss: 1.8150 - val_accuracy: 0.4233\n",
            "Epoch 3/30\n",
            "782/782 [==============================] - 47s 60ms/step - loss: 1.7298 - accuracy: 0.4594 - val_loss: 1.9371 - val_accuracy: 0.3938\n",
            "Epoch 4/30\n",
            "782/782 [==============================] - 47s 60ms/step - loss: 1.6369 - accuracy: 0.4947 - val_loss: 1.5378 - val_accuracy: 0.5361\n",
            "Epoch 5/30\n",
            "782/782 [==============================] - 47s 60ms/step - loss: 1.5955 - accuracy: 0.5204 - val_loss: 1.4492 - val_accuracy: 0.5784\n",
            "Epoch 6/30\n",
            "782/782 [==============================] - 47s 60ms/step - loss: 1.5460 - accuracy: 0.5443 - val_loss: 1.4586 - val_accuracy: 0.5787\n",
            "Epoch 7/30\n",
            "782/782 [==============================] - 47s 60ms/step - loss: 1.5155 - accuracy: 0.5577 - val_loss: 1.6652 - val_accuracy: 0.5309\n",
            "Epoch 8/30\n",
            "782/782 [==============================] - 47s 60ms/step - loss: 1.4872 - accuracy: 0.5712 - val_loss: 1.6030 - val_accuracy: 0.5567\n",
            "Epoch 9/30\n",
            "782/782 [==============================] - 47s 60ms/step - loss: 1.4636 - accuracy: 0.5852 - val_loss: 1.3450 - val_accuracy: 0.6286\n",
            "Epoch 10/30\n",
            "782/782 [==============================] - 47s 60ms/step - loss: 1.4489 - accuracy: 0.5904 - val_loss: 1.3121 - val_accuracy: 0.6398\n",
            "Epoch 11/30\n",
            "782/782 [==============================] - 47s 60ms/step - loss: 1.4222 - accuracy: 0.6035 - val_loss: 1.3633 - val_accuracy: 0.6317\n",
            "Epoch 12/30\n",
            "782/782 [==============================] - 47s 60ms/step - loss: 1.4079 - accuracy: 0.6067 - val_loss: 1.7062 - val_accuracy: 0.5429\n",
            "Epoch 13/30\n",
            "782/782 [==============================] - 47s 60ms/step - loss: 1.3800 - accuracy: 0.6166 - val_loss: 1.2445 - val_accuracy: 0.6634\n",
            "Epoch 14/30\n",
            "782/782 [==============================] - 47s 60ms/step - loss: 1.3718 - accuracy: 0.6213 - val_loss: 1.3775 - val_accuracy: 0.6255\n",
            "Epoch 15/30\n",
            "782/782 [==============================] - 47s 60ms/step - loss: 1.3635 - accuracy: 0.6215 - val_loss: 1.2786 - val_accuracy: 0.6548\n",
            "Epoch 16/30\n",
            "782/782 [==============================] - 47s 60ms/step - loss: 1.3439 - accuracy: 0.6318 - val_loss: 1.2502 - val_accuracy: 0.6657\n",
            "Epoch 17/30\n",
            "782/782 [==============================] - 47s 60ms/step - loss: 1.3236 - accuracy: 0.6373 - val_loss: 1.2384 - val_accuracy: 0.6689\n",
            "Epoch 18/30\n",
            "782/782 [==============================] - 47s 60ms/step - loss: 1.3173 - accuracy: 0.6385 - val_loss: 1.1671 - val_accuracy: 0.6933\n",
            "Epoch 19/30\n",
            "782/782 [==============================] - 47s 60ms/step - loss: 1.3094 - accuracy: 0.6442 - val_loss: 1.3234 - val_accuracy: 0.6482\n",
            "Epoch 20/30\n",
            "782/782 [==============================] - 47s 60ms/step - loss: 1.3057 - accuracy: 0.6441 - val_loss: 1.1578 - val_accuracy: 0.6906\n",
            "Epoch 21/30\n",
            "782/782 [==============================] - 47s 60ms/step - loss: 1.2882 - accuracy: 0.6494 - val_loss: 1.2333 - val_accuracy: 0.6763\n",
            "Epoch 22/30\n",
            "782/782 [==============================] - 47s 60ms/step - loss: 1.2877 - accuracy: 0.6528 - val_loss: 1.2016 - val_accuracy: 0.6804\n",
            "Epoch 23/30\n",
            "782/782 [==============================] - 47s 60ms/step - loss: 1.2693 - accuracy: 0.6564 - val_loss: 1.2229 - val_accuracy: 0.6769\n",
            "Epoch 24/30\n",
            "782/782 [==============================] - 47s 60ms/step - loss: 1.2678 - accuracy: 0.6575 - val_loss: 1.1527 - val_accuracy: 0.6983\n",
            "Epoch 25/30\n",
            "782/782 [==============================] - 47s 60ms/step - loss: 1.2550 - accuracy: 0.6626 - val_loss: 1.1929 - val_accuracy: 0.6860\n",
            "Epoch 26/30\n",
            "782/782 [==============================] - 47s 60ms/step - loss: 1.2477 - accuracy: 0.6641 - val_loss: 1.1114 - val_accuracy: 0.7103\n",
            "Epoch 27/30\n",
            "782/782 [==============================] - 47s 60ms/step - loss: 1.2424 - accuracy: 0.6657 - val_loss: 1.2251 - val_accuracy: 0.6748\n",
            "Epoch 28/30\n",
            "782/782 [==============================] - 47s 60ms/step - loss: 1.2344 - accuracy: 0.6691 - val_loss: 1.1621 - val_accuracy: 0.6911\n",
            "Epoch 29/30\n",
            "782/782 [==============================] - 47s 60ms/step - loss: 1.2279 - accuracy: 0.6706 - val_loss: 1.1401 - val_accuracy: 0.7014\n",
            "Epoch 30/30\n",
            "782/782 [==============================] - 47s 60ms/step - loss: 1.2249 - accuracy: 0.6732 - val_loss: 1.1920 - val_accuracy: 0.6922\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h0IZPzNILb9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7MceMrLCi6-v"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}